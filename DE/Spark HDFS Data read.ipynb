{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "edb5c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "import pyspark\n",
    "import pyspark.sql.functions as f \n",
    "from pymongo import MongoClient\n",
    "\n",
    "spark = SparkSession.builder.appName(\"example-pyspark-read-and-write\").getOrCreate()\n",
    "\n",
    "disp = spark.read.parquet(\"hdfs://localhost:9000/data/coronaAPI\")\n",
    "disp_st = spark.read.parquet(\"hdfs://localhost:9000/data/coronaStage\")\n",
    "\n",
    "df = disp.select('날짜','area','확진자수')\n",
    "df = df.withColumn('date',f.to_date(df['날짜']))\n",
    "df = df.withColumn('date_st',df.date.cast(StringType()))\n",
    "df = df.drop('날짜','date')\n",
    "\n",
    "# df.select(df.date.cast(StringType()).alias('ages')).show()\n",
    "# df = df.date.cast(\"string\")\n",
    "#df.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "82add127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = disp_st.drop('__index_level_0__')\n",
    "df = df.join(df1,'area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "49dc8163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----------+------+------------------------------+\n",
      "|area|확진자수|   date_st| Stage|                   Description|\n",
      "+----+--------+----------+------+------------------------------+\n",
      "|제주|    2803|2021-09-22|3 단계|   - 제주 전지역 4단계 (21....|\n",
      "|경남|   10983|2021-09-22|3 단계|   - 경남 전지역 3단계 (21....|\n",
      "|경북|    7848|2021-09-22|3 단계|  - 경북 일부지역 3단계 (21...|\n",
      "|전남|    2933|2021-09-22|3 단계|   - 전남 전지역 3단계 (21....|\n",
      "|전북|    4179|2021-09-22|3 단계|  - 전북 일부지역 3단계 (21...|\n",
      "|충남|    8627|2021-09-22|3 단계|   - 충남 전지역 3단계 (21....|\n",
      "|충북|    5906|2021-09-22|3 단계|   - 충북 전지역 3단계 (21....|\n",
      "|강원|    6172|2021-09-22|3 단계|- 강원 춘천시, 원주시, 동해...|\n",
      "|경기|   84038|2021-09-22|4 단계|   - 경기 전지역 4단계 (21....|\n",
      "|세종|    1165|2021-09-22|3 단계|   - 세종 전지역 3단계 (21....|\n",
      "|울산|    4991|2021-09-22|3 단계|   - 울산 전지역 3단계 (21....|\n",
      "|대전|    6611|2021-09-22|3 단계|   - 대전 전지역 3단계 (21....|\n",
      "|광주|    4761|2021-09-22|3 단계|   - 광주 전지역 3단계 (21....|\n",
      "|인천|   14719|2021-09-22|4 단계|  - 인천 일부지역 4단계 (21...|\n",
      "|대구|   14687|2021-09-22|3 단계|   - 대구 전지역 3단계 (21....|\n",
      "|부산|   12421|2021-09-22|3 단계|   - 부산 전지역 3단계 (21....|\n",
      "|서울|   93821|2021-09-22|4 단계|   - 서울 전지역 4단계 (21....|\n",
      "|제주|    2794|2021-09-21|3 단계|   - 제주 전지역 4단계 (21....|\n",
      "|경남|   10955|2021-09-21|3 단계|   - 경남 전지역 3단계 (21....|\n",
      "|경북|    7827|2021-09-21|3 단계|  - 경북 일부지역 3단계 (21...|\n",
      "+----+--------+----------+------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "32007488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area': '대구',\n",
       " '확진자수': 11830,\n",
       " 'date_st': '2021-08-03',\n",
       " 'Stage': '3 단계',\n",
       " 'Description': '- 대구 전지역 3단계 (21.9.6~10.3.)'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in df.collect():\n",
    "   a= i.asDict()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bc6c5d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'asDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-8c4bf55ad1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1644\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1645\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'asDict'"
     ]
    }
   ],
   "source": [
    "df.asDict().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd67d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing_load.py\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ojo_test\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017\") \\\n",
    "    .config(\"spark.mongodb.input.database\",\"ojo_db\") \\\n",
    "    .config(\"spark.mongodb.input.collection\", \"test\") \\\n",
    "    .config(\"packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .getOrCreate()\n",
    "sc =spark.sparkContext\n",
    "\n",
    "# pymongo connect\n",
    "client = MongoClient('localhost',27017) # mongodb 27017 port\n",
    "db = client.ojo_db\n",
    "\n",
    "for i in df.collect():\n",
    "    db.test.insert_one(i.asDict())\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51accf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
